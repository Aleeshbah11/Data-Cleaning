{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOT250excs8jerS/E6+J7+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleeshbah11/Data-Cleaning/blob/main/FeatureEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "In ML consists of four main steps:\n",
        "1. Feature Creation\n",
        "2. Transformations\n",
        "3. Feature Extraction\n",
        "4. Feature Selection"
      ],
      "metadata": {
        "id": "E4uTLukrViEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BINNING\n",
        "\n",
        "Binning is also called discretization is a feature engineering technique where continuous numerical data is divided into discrete intervals (bins or categories). It helps in reducing noise and can improve performance in some models.\n",
        "Use it when your data is highly skewed (to reduce variability) or when working with decision trees (categorical data may help). also for creating categories in domain-specific cases (e.g., age groups)."
      ],
      "metadata": {
        "id": "xELXtnvjWLnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equal Width Binning\n",
        "Divides data into bins of equal size (width).\n",
        "\n",
        "for example;\n",
        "The dataset is divided into 3 equal-width bins.\n",
        "The labels (\"Low\", \"Medium\", \"High\") assign categories to each bin."
      ],
      "metadata": {
        "id": "mPHFFMhRWgxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample continuous data\n",
        "data = {'value': np.random.randint(1, 100, 10)}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply equal-width binning (3 bins)\n",
        "df['equal_width_bins'] = pd.cut(df['value'], bins=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "lJ1DlRXuWb1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply equal-frequency binning (3 bins)\n",
        "\n",
        "df['equal_freq_bins'] = pd.qcut(df['value'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "P559uRUhYtP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom binning\n",
        "\n",
        "bins = [0, 30, 60, 100]  # Ranges: (0-30), (30-60), (60-100)\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "\n",
        "# Apply custom binning\n",
        "df['custom_bins'] = pd.cut(df['value'], bins=bins, labels=labels)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "DDgEna-JYoBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ONE HOT ENCODING\n",
        "- It is used to convert categorical data into numerical data.\n",
        "- Why? because duhhh\n",
        "- ML models cannot [digest] categories. the input needs to be a number\n",
        "- It is used for nominal category where rank of catefories does not matter.\n",
        "- one-hot encoding creates binary columns for each category and assign number according to its presence or absence"
      ],
      "metadata": {
        "id": "ZzZHO0L2Gykk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual\n",
        "- Lets code the technique manually first to grasp the concept\n"
      ],
      "metadata": {
        "id": "rn7KksyoHalp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVRG1jEOGuYs",
        "outputId": "6d94e170-b7be-41cf-99fc-ebdb7ed50f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Red', 'Blue', 'Green', 'Blue', 'Red']\n",
            "   Red  Blue  Green\n",
            "0  1.0   0.0    0.0\n",
            "1  0.0   1.0    0.0\n",
            "2  0.0   0.0    1.0\n",
            "3  0.0   1.0    0.0\n",
            "4  1.0   0.0    0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample categorical data\n",
        "categories = ['Red', 'Blue', 'Green', 'Blue', 'Red']\n",
        "# using set() to get unique categories\n",
        "unique_categories = list(set(categories))\n",
        "\n",
        "# Creating one-hot encoding manually\n",
        "one_hot_encoded = np.zeros((len(categories), len(unique_categories)))\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    one_hot_encoded[i, unique_categories.index(category)] = 1\n",
        "\n",
        "# Converting to DataFrame\n",
        "encoded_df = pd.DataFrame(one_hot_encoded, columns=unique_categories)\n",
        "print(categories)\n",
        "print(encoded_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SKLEARN\n",
        "- using SKlearn for onehotencoding"
      ],
      "metadata": {
        "id": "mumZ3BelIPX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "data = [['Red'], ['Blue'], ['Green'], ['Blue'], ['Red']]\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_array = encoder.fit_transform(data)\n",
        "\n",
        "# Converting to DataFrame for better visualization\n",
        "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(['Color']))\n",
        "\n",
        "print(encoded_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQKV1-HkIZ4u",
        "outputId": "38079b78-0fa2-4446-d51c-f5697f5e002a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Red\n",
            "0         0.0          0.0        1.0\n",
            "1         1.0          0.0        0.0\n",
            "2         0.0          1.0        0.0\n",
            "3         1.0          0.0        0.0\n",
            "4         0.0          0.0        1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas\n",
        "- using pandas.get_dummies()"
      ],
      "metadata": {
        "id": "Kfluvg94Iflp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Applying one-hot encoding\n",
        "encoded_df = pd.get_dummies(df, columns=['Color'])\n",
        "\n",
        "print(encoded_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocHf_duRIiYK",
        "outputId": "a49b9c8d-01e8-48c4-d7a6-bf730522da74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Red\n",
            "0       False        False       True\n",
            "1        True        False      False\n",
            "2       False         True      False\n",
            "3        True        False      False\n",
            "4       False        False       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'color': ['red','blue','green','purple','yellow','red','blue']}\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "encoded_df = pd.get_dummies(df,columns=['color'])\n",
        "print(encoded_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ra7Xlv5O7ZW",
        "outputId": "4c5273b8-aebe-4676-a6c2-88114977e763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   color_blue  color_green  color_purple  color_red  color_yellow\n",
            "0       False        False         False       True         False\n",
            "1        True        False         False      False         False\n",
            "2       False         True         False      False         False\n",
            "3       False        False          True      False         False\n",
            "4       False        False         False      False          True\n",
            "5       False        False         False       True         False\n",
            "6        True        False         False      False         False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = ['red','blue','green']\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "encoded_df=pd.get_dummies(df)\n",
        "print(encoded_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8oRDz0SP63C",
        "outputId": "f804eba3-8d7e-4b70-be16-c556760c3240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0_blue  0_green  0_red\n",
            "0   False    False   True\n",
            "1    True    False  False\n",
            "2   False     True  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Target Encoding"
      ],
      "metadata": {
        "id": "jpd5DRfJJqfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pandas"
      ],
      "metadata": {
        "id": "jJ7p5wWnJt-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
        "                 'New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n",
        "        'Target': [1, 0, 1, 0, 1, 1, 1, 0, 1, 0]}  # Binary target variable\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute the mean of the target variable for each category\n",
        "city_target_mean = df.groupby('City')['Target'].mean()\n",
        "\n",
        "# Map the computed mean to the original dataset\n",
        "df['City_Encoded'] = df['City'].map(city_target_mean)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywS9saI2JwAe",
        "outputId": "e55b1e85-51aa-4964-df3b-24b254691e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  Target  City_Encoded\n",
            "0     New York       1           1.0\n",
            "1  Los Angeles       0           0.5\n",
            "2      Chicago       1           0.5\n",
            "3      Houston       0           0.5\n",
            "4      Phoenix       1           0.5\n",
            "5     New York       1           1.0\n",
            "6  Los Angeles       1           0.5\n",
            "7      Chicago       0           0.5\n",
            "8      Houston       1           0.5\n",
            "9      Phoenix       0           0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using CategoryEncoders from category_encoders Library"
      ],
      "metadata": {
        "id": "0zSCU7WrJ0U9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "\n",
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "\n",
        "df = pd.DataFrame({'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
        "                            'New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n",
        "                   'Target': [1, 0, 1, 0, 1, 1, 1, 0, 1, 0]})\n",
        "\n",
        "# Initialize and apply target encoder\n",
        "target_encoder = ce.TargetEncoder(cols=['City'])\n",
        "df['City_Encoded'] = target_encoder.fit_transform(df['City'], df['Target'])\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyU16vnZJ2P5",
        "outputId": "d0ed2575-3209-4a52-8d1e-92aefe614069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.0\n",
            "          City  Target  City_Encoded\n",
            "0     New York       1      0.656740\n",
            "1  Los Angeles       0      0.585815\n",
            "2      Chicago       1      0.585815\n",
            "3      Houston       0      0.585815\n",
            "4      Phoenix       1      0.585815\n",
            "5     New York       1      0.656740\n",
            "6  Los Angeles       1      0.585815\n",
            "7      Chicago       0      0.585815\n",
            "8      Houston       1      0.585815\n",
            "9      Phoenix       0      0.585815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Target Leakage with Cross-Validation"
      ],
      "metadata": {
        "id": "IhdJQ5yzKFjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Sample dataset\n",
        "df = pd.DataFrame({'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
        "                            'New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n",
        "                   'Target': [1, 0, 1, 0, 1, 1, 1, 0, 1, 0]})\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "df['City_Encoded'] = 0\n",
        "\n",
        "for train_idx, val_idx in kf.split(df):\n",
        "    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n",
        "    city_target_mean = train_df.groupby('City')['Target'].mean()\n",
        "    df.loc[val_idx, 'City_Encoded'] = df.loc[val_idx, 'City'].map(city_target_mean)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4C6qpDRKDXq",
        "outputId": "44e34000-1de0-486d-b6e7-3c2247000095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  Target  City_Encoded\n",
            "0     New York       1           NaN\n",
            "1  Los Angeles       0           1.0\n",
            "2      Chicago       1           NaN\n",
            "3      Houston       0           1.0\n",
            "4      Phoenix       1           NaN\n",
            "5     New York       1           NaN\n",
            "6  Los Angeles       1           0.0\n",
            "7      Chicago       0           NaN\n",
            "8      Houston       1           0.0\n",
            "9      Phoenix       0           NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Encoding for Ordinal Categories\n",
        "\n",
        "Best for:\n",
        "\n",
        "Ordinal categorical features (e.g., education level, customer ratings).\n",
        "Tree-based models (XGBoost, LightGBM, Random Forest).\n",
        "\n",
        "Avoid when:\n",
        "\n",
        "Using linear models, as it introduces dependencies.\n",
        "The dataset is small, since mean encoding can lead to overfitting."
      ],
      "metadata": {
        "id": "Oq9mdhXSKXUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {'Education_Level': ['High School', 'Bachelor', 'Master', 'PhD', 'High School',\n",
        "                            'Bachelor', 'Master', 'PhD', 'High School', 'Bachelor'],\n",
        "        'Salary': [40, 60, 80, 100, 45, 65, 85, 105, 38, 62]}  # Target variable\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute the mean salary for each education level\n",
        "education_mean = df.groupby('Education_Level')['Salary'].mean()\n",
        "\n",
        "# Map the computed mean to the original dataset\n",
        "df['Education_Encoded'] = df['Education_Level'].map(education_mean)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9rxGjTIKavH",
        "outputId": "1d525e6e-5d04-42b7-c12a-d84cafe119ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Education_Level  Salary  Education_Encoded\n",
            "0     High School      40          41.000000\n",
            "1        Bachelor      60          62.333333\n",
            "2          Master      80          82.500000\n",
            "3             PhD     100         102.500000\n",
            "4     High School      45          41.000000\n",
            "5        Bachelor      65          62.333333\n",
            "6          Master      85          82.500000\n",
            "7             PhD     105         102.500000\n",
            "8     High School      38          41.000000\n",
            "9        Bachelor      62          62.333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Mean Encoding with category_encoders"
      ],
      "metadata": {
        "id": "HSIXhKRSKedE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "# Initialize mean encoder\n",
        "mean_encoder = ce.TargetEncoder(cols=['Education_Level'])\n",
        "\n",
        "# Apply mean encoding\n",
        "df['Education_Encoded'] = mean_encoder.fit_transform(df['Education_Level'], df['Salary'])\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P4FtNrVKfox",
        "outputId": "55a69faf-5ebb-4f5a-c898-b00d00800c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Education_Level  Salary  Education_Encoded\n",
            "0     High School      40          63.829438\n",
            "1        Bachelor      60          67.124697\n",
            "2          Master      80          70.056840\n",
            "3             PhD     100          72.893862\n",
            "4     High School      45          63.829438\n",
            "5        Bachelor      65          67.124697\n",
            "6          Master      85          70.056840\n",
            "7             PhD     105          72.893862\n",
            "8     High School      38          63.829438\n",
            "9        Bachelor      62          67.124697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Preventing Data Leakage Using Cross-Validation\n",
        "\n",
        "A risk of mean encoding is data leakage, where the target values influence encoding in a way that inflates model performance. To mitigate this, use cross-validation encoding"
      ],
      "metadata": {
        "id": "HePCKLb5Kiqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "df['Education_Encoded'] = 0\n",
        "\n",
        "for train_idx, val_idx in kf.split(df):\n",
        "    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n",
        "    mean_values = train_df.groupby('Education_Level')['Salary'].mean()\n",
        "    df.loc[val_idx, 'Education_Encoded'] = df.loc[val_idx, 'Education_Level'].map(mean_values)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAWUEKYFKkPv",
        "outputId": "989b6df7-e4a4-4a21-c445-ab17f976de08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Education_Level  Salary  Education_Encoded\n",
            "0     High School      40               41.5\n",
            "1        Bachelor      60               63.5\n",
            "2          Master      80               85.0\n",
            "3             PhD     100              105.0\n",
            "4     High School      45               39.0\n",
            "5        Bachelor      65               61.0\n",
            "6          Master      85               80.0\n",
            "7             PhD     105              100.0\n",
            "8     High School      38               42.5\n",
            "9        Bachelor      62               62.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b5b439830ee6>:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[63.5 42.5]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[val_idx, 'Education_Encoded'] = df.loc[val_idx, 'Education_Level'].map(mean_values)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice"
      ],
      "metadata": {
        "id": "NM1LyzP_MtUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding\n",
        "\n",
        "Best for Nominal data for unordered categories. Increases the number of columns significantly for high-cardinality categories."
      ],
      "metadata": {
        "id": "LErMvnWgNH7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Red', 'Green']})\n",
        "df_encoded = pd.get_dummies(df, columns=['Color'])\n",
        "print(df_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcA9JChxNOes",
        "outputId": "e3a167cf-b8b1-48d0-f258-95f2a68c336b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Red\n",
            "0       False        False       True\n",
            "1        True        False      False\n",
            "2       False         True      False\n",
            "3       False        False       True\n",
            "4       False         True      False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding\n",
        "\n",
        "Best for Ordinal data ordered categories, Introduces artificial numerical relationships for nominal categories"
      ],
      "metadata": {
        "id": "NB9_kumoM9AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.DataFrame({'Size': ['Small', 'Medium', 'Large', 'Small', 'Large']})\n",
        "encoder = LabelEncoder()\n",
        "df['Size_Encoded'] = encoder.fit_transform(df['Size'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUBaC2QhNBKb",
        "outputId": "e8f9012d-7527-4f9b-89e0-a55fc8e4f891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Size  Size_Encoded\n",
            "0   Small             2\n",
            "1  Medium             1\n",
            "2   Large             0\n",
            "3   Small             2\n",
            "4   Large             0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Ordinal Encoding\n",
        "\n",
        "Best for Ordinal categories e.g., education level, Requires correct ordering of values"
      ],
      "metadata": {
        "id": "DnC9ZhaLM3cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "df = pd.DataFrame({'Education': ['High School', 'Bachelor', 'Master', 'PhD', 'Bachelor']})\n",
        "encoder = OrdinalEncoder(categories=[['High School', 'Bachelor', 'Master', 'PhD']])\n",
        "df['Education_Encoded'] = encoder.fit_transform(df[['Education']])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkXBQ4tFM7aI",
        "outputId": "6ea488ec-8f1a-4557-9e85-476a8a5e6b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Education  Education_Encoded\n",
            "0  High School                0.0\n",
            "1     Bachelor                1.0\n",
            "2       Master                2.0\n",
            "3          PhD                3.0\n",
            "4     Bachelor                1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Target Encoding (Mean Encoding)\n",
        "\n",
        "Best for High-cardinality featuresCan cause data leakage if not handled properly."
      ],
      "metadata": {
        "id": "fDmU5FhHMuvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "\n",
        "df = pd.DataFrame({'City': ['NY', 'LA', 'SF', 'NY', 'LA'], 'Price': [100, 200, 300, 150, 250]})\n",
        "encoder = ce.TargetEncoder(cols=['City'])\n",
        "df['City_Encoded'] = encoder.fit_transform(df['City'], df['Price'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSO8CZxaMz5w",
        "outputId": "b2e7bc26-5cff-4e29-bd5e-e7b570d7ad98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  City  Price  City_Encoded\n",
            "0   NY    100    189.361170\n",
            "1   LA    200    203.546277\n",
            "2   SF    300    213.010847\n",
            "3   NY    150    189.361170\n",
            "4   LA    250    203.546277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequency Encoding\n",
        "\n",
        "Best for High-cardinality features. May lose information if all categories have similar frequencies"
      ],
      "metadata": {
        "id": "I65RFqKELHln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'City': ['NY', 'LA', 'SF', 'NY', 'LA']})\n",
        "df['City_Encoded'] = df['City'].map(df['City'].value_counts() / len(df))\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhlih4mYLE24",
        "outputId": "a2bbedd1-ea0b-4ae3-8ccb-ebd7aa049b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  City  City_Encoded\n",
            "0   NY           0.4\n",
            "1   LA           0.4\n",
            "2   SF           0.2\n",
            "3   NY           0.4\n",
            "4   LA           0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Encoding\n",
        "Best for Reducing dimensionality while keeping unique representations, still increases the number of columns but less than One-Hot Encoding."
      ],
      "metadata": {
        "id": "MUVtOtHrLQYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "df = pd.DataFrame({'Category': ['A', 'B', 'C', 'D', 'E']})\n",
        "encoder = ce.BinaryEncoder(cols=['Category'])\n",
        "df_encoded = encoder.fit_transform(df)\n",
        "print(df_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dofJK5FHLS96",
        "outputId": "70091754-03d5-46a7-f464-bde989fff0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category_0  Category_1  Category_2\n",
            "0           0           0           1\n",
            "1           0           1           0\n",
            "2           0           1           1\n",
            "3           1           0           0\n",
            "4           1           0           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hash Encoding Hashing Trick\n",
        " Best for High-cardinality categorical data\n",
        " Possible collisions when two different categories mapping to the same value."
      ],
      "metadata": {
        "id": "VnkXIXhJLd9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = ce.HashingEncoder(cols=['Category'], n_components=3)  # Number of hash bins\n",
        "df_encoded = encoder.fit_transform(df)\n",
        "print(df_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZZCab-1LeZU",
        "outputId": "1487ee0f-4c93-4b33-dc93-e94bf1cfd27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   col_0  col_1  col_2\n",
            "0      0      1      0\n",
            "1      0      1      0\n",
            "2      0      1      0\n",
            "3      0      0      1\n",
            "4      0      1      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Weight of Evidence (WoE) Encoding\n",
        "Best for Binary classification problems. Works only when the target variable is binary.\n",
        "\n",
        "WoE=log(\n",
        "P(Bad)/\n",
        "P(Good)\n",
        "​\n",
        " )\n",
        "\n",
        "\n",
        "𝑃\n",
        "(\n",
        "Good\n",
        ")\n",
        "P(Good) = Percentage of positive target (e.g., Salary > 75000)\n",
        "𝑃\n",
        "(\n",
        "Bad\n",
        ")\n",
        "P(Bad) = Percentage of negative target (e.g., Salary <= 75000)"
      ],
      "metadata": {
        "id": "z-j-TWYBLof0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame({'Feature': ['A', 'B', 'C', 'A', 'B', 'C'], 'Target': [1, 0, 1, 1, 0, 0]})\n",
        "\n",
        "# Compute WoE\n",
        "woe_df = df.groupby('Feature')['Target'].agg(['sum', 'count'])\n",
        "woe_df['WoE'] = np.log((woe_df['sum'] + 1) / (woe_df['count'] - woe_df['sum'] + 1))\n",
        "\n",
        "# Map to original data\n",
        "df['Feature_WoE'] = df['Feature'].map(woe_df['WoE'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kq4vzeHLumS",
        "outputId": "8719709a-712d-4cf8-9458-38c4cd0a454c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature  Target  Feature_WoE\n",
            "0       A       1     1.098612\n",
            "1       B       0    -1.098612\n",
            "2       C       1     0.000000\n",
            "3       A       1     1.098612\n",
            "4       B       0    -1.098612\n",
            "5       C       0     0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "Encode the \"City\" column in a dataset using multiple encoding techniques"
      ],
      "metadata": {
        "id": "xBrt4Q6EOxpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'New York', 'Chicago', 'Houston'],\n",
        "    'Salary': [70000, 80000, 75000, 72000, 68000, 73000, 77000, 71000]  # Target variable\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-KHiEzuOz8f",
        "outputId": "865cb406-986e-4a96-c43c-74fe3e520c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  Salary\n",
            "0     New York   70000\n",
            "1  Los Angeles   80000\n",
            "2      Chicago   75000\n",
            "3      Houston   72000\n",
            "4      Phoenix   68000\n",
            "5     New York   73000\n",
            "6      Chicago   77000\n",
            "7      Houston   71000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OHE\n",
        "\n",
        "# Issue: More columns = higher memory usage.\n",
        "\n",
        "df_ohe = pd.get_dummies(df, columns=['City'])\n",
        "print(df_ohe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCJRRgfKO793",
        "outputId": "19b0667e-f0e8-4323-e040-cdefffb16dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Salary  City_Chicago  City_Houston  City_Los Angeles  City_New York  \\\n",
            "0   70000         False         False             False           True   \n",
            "1   80000         False         False              True          False   \n",
            "2   75000          True         False             False          False   \n",
            "3   72000         False          True             False          False   \n",
            "4   68000         False         False             False          False   \n",
            "5   73000         False         False             False           True   \n",
            "6   77000          True         False             False          False   \n",
            "7   71000         False          True             False          False   \n",
            "\n",
            "   City_Phoenix  \n",
            "0         False  \n",
            "1         False  \n",
            "2         False  \n",
            "3         False  \n",
            "4          True  \n",
            "5         False  \n",
            "6         False  \n",
            "7         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding\n",
        "\n",
        "#It creates an artificial order between cities.\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df['City_Label'] = encoder.fit_transform(df['City'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA5b6CiUO-0i",
        "outputId": "3183ce7b-1944-4916-b6bb-fec4e8661749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  Salary  City_Label\n",
            "0     New York   70000           3\n",
            "1  Los Angeles   80000           2\n",
            "2      Chicago   75000           0\n",
            "3      Houston   72000           1\n",
            "4      Phoenix   68000           4\n",
            "5     New York   73000           3\n",
            "6      Chicago   77000           0\n",
            "7      Houston   71000           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Encoding (Mean Encoding)\n",
        "\n",
        "# If not done correctly, it may lead to data leakage\n",
        "\n",
        "import category_encoders as ce\n",
        "\n",
        "target_encoder = ce.TargetEncoder(cols=['City'])\n",
        "df['City_Target'] = target_encoder.fit_transform(df['City'], df['Salary'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAlV0QQwPCyN",
        "outputId": "ebcb6815-87af-4fe2-b427-d1b475af84da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  Salary  City_Label   City_Target\n",
            "0     New York   70000           3  73001.760636\n",
            "1  Los Angeles   80000           2  74128.232202\n",
            "2      Chicago   75000           0  73640.090428\n",
            "3      Houston   72000           1  73001.760636\n",
            "4      Phoenix   68000           4  72566.930510\n",
            "5     New York   73000           3  73001.760636\n",
            "6      Chicago   77000           0  73640.090428\n",
            "7      Houston   71000           1  73001.760636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency Encoding\n",
        "\n",
        "# Good for high-cardinality features!\n",
        "\n",
        "df['City_Freq'] = df['City'].map(df['City'].value_counts() / len(df))\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trP6238YPEqo",
        "outputId": "832314fc-f8d8-42db-aac6-2b9f3c5c8b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  Salary  City_Label   City_Target  City_Freq\n",
            "0     New York   70000           3  73001.760636      0.250\n",
            "1  Los Angeles   80000           2  74128.232202      0.125\n",
            "2      Chicago   75000           0  73640.090428      0.250\n",
            "3      Houston   72000           1  73001.760636      0.250\n",
            "4      Phoenix   68000           4  72566.930510      0.125\n",
            "5     New York   73000           3  73001.760636      0.250\n",
            "6      Chicago   77000           0  73640.090428      0.250\n",
            "7      Houston   71000           1  73001.760636      0.250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary Encoding\n",
        "\n",
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "df = pd.DataFrame({'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'New York', 'Chicago', 'Houston']})\n",
        "\n",
        "# Apply Binary Encoding\n",
        "encoder = ce.BinaryEncoder(cols=['City'])\n",
        "df_binary = encoder.fit_transform(df)\n",
        "\n",
        "print(df_binary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk6rwEmkPsc_",
        "outputId": "fe7e5c0a-15e5-4331-f6f0-bd0aa7e33fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   City_0  City_1  City_2\n",
            "0       0       0       1\n",
            "1       0       1       0\n",
            "2       0       1       1\n",
            "3       1       0       0\n",
            "4       1       0       1\n",
            "5       0       0       1\n",
            "6       0       1       1\n",
            "7       1       0       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement WoE Encoding\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset with a binary target\n",
        "df = pd.DataFrame({\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'New York', 'Chicago', 'Houston'],\n",
        "    'Salary': [1, 0, 1, 0, 1, 1, 0, 0]  # Binary target (1 = High Salary, 0 = Low Salary)\n",
        "})\n",
        "\n",
        "# Compute WoE\n",
        "woe_df = df.groupby('City')['Salary'].agg(['sum', 'count'])\n",
        "woe_df['WoE'] = np.log((woe_df['sum'] + 1) / (woe_df['count'] - woe_df['sum'] + 1))\n",
        "\n",
        "# Map WoE to original dataset\n",
        "df['City_WoE'] = df['City'].map(woe_df['WoE'])\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbMBPW8VPy99",
        "outputId": "b9378ec7-b53c-4250-c151-a3638c0c7e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  Salary  City_WoE\n",
            "0     New York       1  1.098612\n",
            "1  Los Angeles       0 -0.693147\n",
            "2      Chicago       1  0.000000\n",
            "3      Houston       0 -1.098612\n",
            "4      Phoenix       1  0.693147\n",
            "5     New York       1  1.098612\n",
            "6      Chicago       0  0.000000\n",
            "7      Houston       0 -1.098612\n"
          ]
        }
      ]
    }
  ]
}